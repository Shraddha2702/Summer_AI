{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing, Training, and Deploying a TensorFlow model on Google Cloud Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import datalab.storage as storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up Cloud Environment on your GCP Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change to your bucket and project name, to set up environment in your project, store files in your bucket and to run the model on cloud ml engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure you put the correct values here !!!\n",
    "BUCKET='nyc_servicerequest'\n",
    "PROJECT='summerai'\n",
    "REGION='us-west1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select the data file, date and the target variables that you want to use for the revenue forecast**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://nyc_servicerequest/processedInput/eval2.csv...\n",
      "| [1 files][183.0 MiB/183.0 MiB]                                                \n",
      "Operation completed over 1 objects/183.0 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp gs://nyc_servicerequest/processedInput/eval2.csv eval2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('eval2.csv')[['day_period', 'day_of_week', 'zip_encode',\n",
    "       'location_encode', 'community_encode', 'agency_encode',\n",
    "       'complaint_encode']].to_csv('eval2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://eval2.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run\n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "|\n",
      "Operation completed over 1 objects/166.2 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp 'eval2.csv' gs://nyc_servicerequest/processedInput/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://nyc_servicerequest/encodedInput/train0.csv...\n",
      "- [1 files][ 45.9 MiB/ 45.9 MiB]                                                \n",
      "Operation completed over 1 objects/45.9 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://nyc_servicerequest/encodedInput/train0.csv trainx.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>1.2</th>\n",
       "      <th>3</th>\n",
       "      <th>2.1</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.3</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>1.4</th>\n",
       "      <th>1.273</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>79.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    2  1  1.1  1.2  3  2.1  0  0.1  1.3  0.2  0.3  0.4  1.4   1.273\n",
       "0   5  1    3    1  3    2  0    0    1    0    0    0    1  85.838\n",
       "1   6  1    3    1  3    2  1    0    0    0    1    0    0  59.059\n",
       "2   9  1    3    1  3    2  1    0    0    0    0    0    1  79.434\n",
       "3  10  1    0    1  2    2  0    0    1    0    0    0    1  26.400\n",
       "4  12  1    3    1  2    2  0    0    0    1    1    0    0  24.000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('trainx.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TensorflowTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0728 07:43:24.843147 139966359180736 deprecation_wrapper.py:119] From TensorflowTrainer/model_2.py:12: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W0728 07:43:24.843430 139966359180736 deprecation_wrapper.py:119] From TensorflowTrainer/model_2.py:12: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "I0728 07:43:24.845433 139966359180736 estimator.py:1790] Using default config.\n",
      "I0728 07:43:24.846021 139966359180736 estimator.py:209] Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4c23fc3a50>, '_model_dir': 'nyc_rides_model/', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_experimental_max_worker_delay_secs': None, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n",
      "I0728 07:43:24.846833 139966359180736 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "I0728 07:43:24.847033 139966359180736 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "I0728 07:43:24.847302 139966359180736 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "W0728 07:43:24.871792 139966359180736 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/training_util.py:236: initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0728 07:43:24.881839 139966359180736 deprecation_wrapper.py:119] From TensorflowTrainer/model_2.py:56: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "W0728 07:43:25.021811 139966359180736 deprecation_wrapper.py:119] From TensorflowTrainer/model_2.py:35: The name tf.decode_csv is deprecated. Please use tf.io.decode_csv instead.\n",
      "\n",
      "W0728 07:43:25.066757 139966359180736 deprecation.py:323] From TensorflowTrainer/model_2.py:67: make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "I0728 07:43:25.084861 139966359180736 estimator.py:1145] Calling model_fn.\n",
      "W0728 07:43:25.645447 139966359180736 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "I0728 07:43:26.156929 139966359180736 estimator.py:1147] Done calling model_fn.\n",
      "I0728 07:43:26.157327 139966359180736 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "W0728 07:43:26.337563 139966359180736 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py:1354: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "I0728 07:43:26.557688 139966359180736 monitored_session.py:240] Graph was finalized.\n",
      "2019-07-28 07:43:26.558162: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2019-07-28 07:43:26.570418: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
      "2019-07-28 07:43:26.573457: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562487471e40 executing computations on platform Host. Devices:\n",
      "2019-07-28 07:43:26.573533: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-07-28 07:43:26.575177: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2019-07-28 07:43:26.658856: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "I0728 07:43:26.733623 139966359180736 session_manager.py:500] Running local_init_op.\n",
      "I0728 07:43:26.752243 139966359180736 session_manager.py:502] Done running local_init_op.\n",
      "I0728 07:43:27.433954 139966359180736 basic_session_run_hooks.py:606] Saving checkpoints for 0 into nyc_rides_model/model.ckpt.\n",
      "2019-07-28 07:43:38.200043: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:111] Filling up shuffle buffer (this may take a while): 144909 of 200000\n",
      "2019-07-28 07:43:41.938305: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:162] Shuffle buffer filled.\n",
      "I0728 07:43:43.571002 139966359180736 basic_session_run_hooks.py:262] loss = 33905480.0, step = 1\n",
      "I0728 07:43:43.571650 139966359180736 basic_session_run_hooks.py:606] Saving checkpoints for 1 into nyc_rides_model/model.ckpt.\n",
      "I0728 07:43:43.868159 139966359180736 estimator.py:1145] Calling model_fn.\n",
      "I0728 07:43:44.566129 139966359180736 estimator.py:1147] Done calling model_fn.\n",
      "I0728 07:43:44.583906 139966359180736 evaluation.py:255] Starting evaluation at 2019-07-28T07:43:44Z\n",
      "I0728 07:43:44.715524 139966359180736 monitored_session.py:240] Graph was finalized.\n",
      "W0728 07:43:44.716156 139966359180736 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I0728 07:43:44.717608 139966359180736 saver.py:1280] Restoring parameters from nyc_rides_model/model.ckpt-1\n",
      "I0728 07:43:44.816912 139966359180736 session_manager.py:500] Running local_init_op.\n",
      "I0728 07:43:44.853244 139966359180736 session_manager.py:502] Done running local_init_op.\n",
      "I0728 07:43:45.220047 139966359180736 evaluation.py:275] Finished evaluation at 2019-07-28-07:43:45\n",
      "I0728 07:43:45.220334 139966359180736 estimator.py:2039] Saving dict for global step 1: average_loss = 0.0, global_step = 1, label/mean = 0.0, loss = 0.0, prediction/mean = 0.0\n",
      "I0728 07:43:45.369043 139966359180736 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1: nyc_rides_model/model.ckpt-1\n",
      "W0728 07:43:45.374854 139966359180736 deprecation_wrapper.py:119] From TensorflowTrainer/model_2.py:76: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "I0728 07:43:45.393105 139966359180736 estimator.py:1145] Calling model_fn.\n",
      "I0728 07:43:46.019835 139966359180736 estimator.py:1147] Done calling model_fn.\n",
      "W0728 07:43:46.020162 139966359180736 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "I0728 07:43:46.020869 139966359180736 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
      "I0728 07:43:46.020978 139966359180736 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
      "I0728 07:43:46.021049 139966359180736 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
      "I0728 07:43:46.021095 139966359180736 export_utils.py:170] Signatures INCLUDED in export for Predict: ['predict']\n",
      "I0728 07:43:46.021136 139966359180736 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
      "I0728 07:43:46.021173 139966359180736 export_utils.py:173] Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "I0728 07:43:46.021224 139966359180736 export_utils.py:176] 'serving_default' : Regression input must be a single string Tensor; got {'complaint_encode': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=int32>, 'evening': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=int32>, 'Fri-Sat-Sun': <tf.Tensor 'Placeholder_9:0' shape=(?,) dtype=int32>, 'Wed-Thu': <tf.Tensor 'Placeholder_11:0' shape=(?,) dtype=int32>, 'community_encode': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=int32>, 'agency_encode': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=int32>, 'zip_encode': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=int32>, 'location_encode': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=int32>, 'morning': <tf.Tensor 'Placeholder_7:0' shape=(?,) dtype=int32>, 'afternoon': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=int32>, 'night': <tf.Tensor 'Placeholder_8:0' shape=(?,) dtype=int32>, 'Mon-Tue': <tf.Tensor 'Placeholder_10:0' shape=(?,) dtype=int32>}\n",
      "I0728 07:43:46.021270 139966359180736 export_utils.py:176] 'regression' : Regression input must be a single string Tensor; got {'complaint_encode': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=int32>, 'evening': <tf.Tensor 'Placeholder_6:0' shape=(?,) dtype=int32>, 'Fri-Sat-Sun': <tf.Tensor 'Placeholder_9:0' shape=(?,) dtype=int32>, 'Wed-Thu': <tf.Tensor 'Placeholder_11:0' shape=(?,) dtype=int32>, 'community_encode': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=int32>, 'agency_encode': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=int32>, 'zip_encode': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=int32>, 'location_encode': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=int32>, 'morning': <tf.Tensor 'Placeholder_7:0' shape=(?,) dtype=int32>, 'afternoon': <tf.Tensor 'Placeholder_5:0' shape=(?,) dtype=int32>, 'night': <tf.Tensor 'Placeholder_8:0' shape=(?,) dtype=int32>, 'Mon-Tue': <tf.Tensor 'Placeholder_10:0' shape=(?,) dtype=int32>}\n",
      "W0728 07:43:46.021316 139966359180736 export_utils.py:182] Export includes no default signature!\n",
      "I0728 07:43:46.094255 139966359180736 saver.py:1280] Restoring parameters from nyc_rides_model/model.ckpt-1\n",
      "I0728 07:43:46.135049 139966359180736 builder_impl.py:661] Assets added to graph.\n",
      "I0728 07:43:46.135265 139966359180736 builder_impl.py:456] No assets to write.\n",
      "I0728 07:43:46.245501 139966359180736 builder_impl.py:421] SavedModel written to: nyc_rides_model/export/exporter/temp-1564299825/saved_model.pb\n",
      "I0728 07:43:46.718378 139966359180736 estimator.py:368] Loss for final step: 33905480.0.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf nyc_rides_model\n",
    "python -m TensorflowTrainer.task \\\n",
    "  --train_data_paths=gs://${BUCKET}/encodedInput/train0.csv \\\n",
    "  --eval_data_paths=gs://${BUCKET}/encodedInput/eval0.csv \\\n",
    "  --output_dir=nyc_rides_model \\\n",
    "  --job-dir=./tmp \\\n",
    "  --train_steps=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train in Cloud ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: service_requests_190729_050747\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://nyc_servicerequest/temp/#1563676735737458...\n",
      "Removing gs://nyc_servicerequest/temp/packages/06bc60d77e393414e5754e92531164d0124047c57813c79f3bb8c07ed3080928/DecisionTreeTrainer-0.0.0.tar.gz#1564268238153810...\n",
      "Removing gs://nyc_servicerequest/temp/packages/2599a301f6eb2e1013dd795d93ecfa8bdb35bac5c031f04737c55a0bac505900/DecisionTreeTrainer-0.0.0.tar.gz#1564268711418615...\n",
      "Removing gs://nyc_servicerequest/temp/packages/43854edb9b9a33aca12a997c529163260bfd23491f809241582c29086d5d639c/DecisionTreeTrainer-0.0.0.tar.gz#1564266345837463...\n",
      "/ [4 objects]                                                                   \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m rm ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Removing gs://nyc_servicerequest/temp/packages/5e1a64d2fb42118743058895e6b6246780e4c4a4273e3686284a5c815f394bdb/DecisionTreeTrainer-0.0.0.tar.gz#1564268993354105...\n",
      "Removing gs://nyc_servicerequest/temp/packages/ae2ec2523e22f17f4bdb0524b1b2b74fc438af0341f416bfadc1f74242cf9750/DecisionTreeTrainer-0.0.0.tar.gz#1564268447586496...\n",
      "Removing gs://nyc_servicerequest/temp/packages/c58150742ac250cb3197efe05e2f1895edcc17c780c184bf98c9ba75d561960f/DecisionTreeTrainer-0.0.0.tar.gz#1564264232900302...\n",
      "/ [7 objects]                                                                   \n",
      "Operation completed over 7 objects.                                              \n",
      "Job [service_requests_190729_050747] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe service_requests_190729_050747\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs service_requests_190729_050747\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil rm -r gs://${BUCKET}/staging/\n",
    "JOBNAME=service_requests_$(date -u +%y%m%d_%H%M%S)\n",
    "gcloud ai-platform jobs submit training $JOBNAME \\\n",
    "  --job-dir=gs://${BUCKET}/staging/ \\\n",
    "  --package-path=${PWD}/TensorflowTrainer \\\n",
    "  --module-name=TensorflowTrainer.task \\\n",
    "  --region=us-west1 \\\n",
    "  --runtime-version=1.14 \\\n",
    "  --python-version=2.7 \\\n",
    "  --scale-tier=BASIC \\\n",
    "  -- \\\n",
    "  --train_data_paths=gs://${BUCKET}/encodedInput/train* \\\n",
    "  --eval_data_paths=gs://${BUCKET}/encodedInput/eval*  \\\n",
    "  --output_dir=gs://${BUCKET}/staging/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run below lines to see the Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#gcloud ai-platform jobs describe service_requests_190729_043852"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some 5000 Train steps and 2 hours later  .... .... ... .. .. . Time to deploy !**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create and Delploy the trained job on model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run it only after your Job has completed running**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The `gcloud ml-engine` commands have been renamed and will soon be removed. Please use `gcloud ai-platform` instead.\n",
      "WARNING: `--regions` flag will soon be required. Please explicitly specify a region. Using [us-central1] by default.\n",
      "Created ml engine model [projects/summerai/models/tensorflow_linear_model_2].\n",
      "Creating version (this might take a few minutes)......\n",
      ".............................................................................................................................................................................................................................................................................done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "REGION='us-west1'\n",
    "MODEL_NAME='tensorflow_linear_model_1'\n",
    "MODEL_VERSION='v1'\n",
    "gcloud ml-engine models create $MODEL_NAME\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/staging/export/exporter/ | tail -1)\n",
    "\n",
    "gcloud ai-platform versions create ${MODEL_VERSION} \\\n",
    "--model ${MODEL_NAME} \\\n",
    "--origin ${MODEL_LOCATION} \\\n",
    "--runtime-version=1.14 \\\n",
    "--python-version=2.7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THE MODEL IS DEPLOYED .... YAYYY !!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2019-07-29T05:14:32Z'\n",
      "deploymentUri: gs://nyc_servicerequest/temp/export/exporter/1564377077/\n",
      "etag: 6F8p8kLp3Sc=\n",
      "framework: TENSORFLOW\n",
      "isDefault: true\n",
      "machineType: mls1-c1-m2\n",
      "name: projects/summerai/models/tensorflow_linear_model_2/versions/v1\n",
      "pythonVersion: '2.7'\n",
      "runtimeVersion: '1.14'\n",
      "state: READY\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ai-platform versions describe v1 \\\n",
    "--model='tensorflow_linear_model_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud ML Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Make online Predictions on Evaluation dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.read_csv('localsave2/x_all_eval.csv', header=None).iloc[1:, :]#.as_matrix().tolist()\n",
    "test_labels = pd.read_csv('localsave2/y_all_eval.csv', header=None).iloc[1:, :]#.as_matrix().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features[0] = test_features[0].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_features = test_features.as_matrix().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2380440, 2380440)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_features), len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 1, 1, 2, 0, 0, 1, 0, 1, 0, 0],\n",
       " [1, 0, 3, 1, 0, 2, 0, 1, 0, 0, 0, 1, 0],\n",
       " [2, 0, 3, 1, 0, 2, 1, 0, 0, 0, 0, 0, 1],\n",
       " [3, 0, 3, 1, 0, 2, 0, 0, 0, 1, 0, 0, 1],\n",
       " [4, 0, 3, 1, 0, 2, 0, 1, 0, 0, 0, 0, 1]]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction failed: unknown error.\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient import discovery\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import json\n",
    "\n",
    "PROJECT_ID = 'summerai'\n",
    "VERSION_NAME = 'v1'\n",
    "MODEL_NAME = 'tensorflow_linear_model_2'\n",
    "\n",
    "credentials = GoogleCredentials.get_application_default()\n",
    "api = discovery.build('ml', 'v1', credentials=credentials, cache_discovery=False)\n",
    "\n",
    "test = test_features[:int(len(test_features)/500)]\n",
    "request_data = {\"instances\": test}\n",
    "\n",
    " \n",
    "parent = 'projects/%s/models/%s/versions/%s' % (PROJECT_ID, MODEL_NAME, VERSION_NAME)\n",
    "responses = api.projects().predict(body = request_data, name = parent).execute()\n",
    "if 'error' in responses:\n",
    "    print(responses['error'])\n",
    "else:\n",
    "    # Print the first 10 responses\n",
    "    for i, response in enumerate(responses['predictions'][:10]):\n",
    "        print('Prediction: {}\\t\\tActual: {}'.format(response, test_labels[i][0]))\n",
    "\n",
    "\n",
    "# Due to the size of the data, it needs to be split in 2\n",
    "#data = test_features[:int(len(test_features)/500)]\n",
    "#second_half = test_features[int(len(test_features)/2):]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instances': [['evening',\n",
       "   'Mon-Tue',\n",
       "   'zip_bin4',\n",
       "   'location_bin1',\n",
       "   'community_bin2',\n",
       "   'agency_bin6',\n",
       "   'complaint_bin3'],\n",
       "  ['afternoon',\n",
       "   'Fri-Sat-Sun',\n",
       "   'zip_bin4',\n",
       "   'location_bin1',\n",
       "   'community_bin2',\n",
       "   'agency_bin6',\n",
       "   'complaint_bin3'],\n",
       "  ['morning',\n",
       "   'Mon-Tue',\n",
       "   'zip_bin4',\n",
       "   'location_bin4',\n",
       "   'community_bin2',\n",
       "   'agency_bin5',\n",
       "   'complaint_bin3'],\n",
       "  ['night',\n",
       "   'Wed-Thu',\n",
       "   'zip_bin4',\n",
       "   'location_bin4',\n",
       "   'community_bin2',\n",
       "   'agency_bin5',\n",
       "   'complaint_bin3'],\n",
       "  ['morning',\n",
       "   'Mon-Tue',\n",
       "   'zip_bin4',\n",
       "   'location_bin4',\n",
       "   'community_bin2',\n",
       "   'agency_bin5',\n",
       "   'complaint_bin3']]}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_anaylsis(y_pred, y_actual):\n",
    "    # mean squared error\n",
    "    m = len(y_actual)\n",
    "    \n",
    "    mse = np.sum((y_pred - y_actual)**2)\n",
    "\n",
    "    # root mean squared error\n",
    "    # m is the number of training examples\n",
    "    rmse = np.sqrt(mse/m)\n",
    "    \n",
    "    # sum of square of residuals\n",
    "    ssr = np.sum((y_pred - y_actual)**2)\n",
    "\n",
    "    #  total sum of squares\n",
    "    sst = np.sum((y_actual - np.mean(y_actual))**2)\n",
    "\n",
    "    # R2 score\n",
    "    r2_score = 1 - (ssr/sst)\n",
    "    \n",
    "    return mse, rmse, ssr, sst, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse, rmse, ssr, sst, r2_score = error_anaylsis(responses['predictions'], np.concatenate(test_labels[:int(len(test_features)/100)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE for the Linear Regression model on the whole dataset \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
