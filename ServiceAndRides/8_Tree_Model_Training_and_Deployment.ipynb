{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://cloud.google.com/ml-engine/docs/scikit/getting-started-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model on AI Platform  \n",
    "- Create Python training module\n",
    "    - Add code to download the data from Cloud Storage so that AI platform can use it . \n",
    "    - Add code to export and save the model to Cloud Storage after AI platform finishes training the model . \n",
    "   \n",
    "- Prepare a training application package .  \n",
    "    \n",
    "- Submit the training job     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since I am using an sklearn model, the deployment code and trainer module will have slight changes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order the train the model on GCS, the data needs to be stored preprocessed (Converting Categorical to Numerical features) and for the sklearn model, the Features and Target labels needs to be stored in different files. Let's go ahead and implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = ['zip_encode', 'location_encode', 'community_encode', 'agency_encode',\n",
    "       'complaint_encode', 'afternoon', 'evening', 'morning', 'night',\n",
    "       'Fri-Sat-Sun', 'Mon-Tue', 'Wed-Thu']\n",
    "y_col = 'TimeTaken'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['index', 'day_period', 'day_of_week', \\\n",
    "             'zip_encode', 'location_encode', \\\n",
    "             'community_encode', 'agency_encode', \\\n",
    "             'complaint_encode', 'TimeTaken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bucket where files are saved\n",
    "path = 'gs://nyc_servicerequest/processedInput/*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downloading files from the GCS Storage bucket for preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://nyc_servicerequest/processedInput/evalx2.csv...\n",
      "| [1 files][180.4 MiB/180.4 MiB]                                                \n",
      "Operation completed over 1 objects/180.4 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp 'gs://nyc_servicerequest/processedInput/evalx2.csv' 'localsave/eval2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(os.listdir('localsave'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download each file, save locally and upload onto bucket again.\n",
    "for each in files[6:]:\n",
    "    try:\n",
    "        df = pd.read_csv('localsave/'+each, header=None)\n",
    "        df.columns = cols\n",
    "        df.drop('index', axis=1, inplace=True)\n",
    "\n",
    "        one_hot_dp = pd.get_dummies(df['day_period'])\n",
    "        df = df.drop('day_period', axis=1)\n",
    "        df = df.join(one_hot_dp)\n",
    "\n",
    "        one_hot_week = pd.get_dummies(df['day_of_week'])\n",
    "        df = df.drop('day_of_week', axis=1)\n",
    "        df = df.join(one_hot_week)\n",
    "\n",
    "        df_new = df[['zip_encode', 'location_encode', 'community_encode', 'agency_encode',\n",
    "               'complaint_encode']].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "        df_old = df[['afternoon', 'evening', 'morning',\n",
    "            'night', 'Fri-Sat-Sun', 'Mon-Tue', 'Wed-Thu','TimeTaken']]\n",
    "\n",
    "        ddf = pd.concat([df_new, df_old], axis=1)\n",
    "\n",
    "        df1 = ddf[ddf['TimeTaken'] < 100]\n",
    "        df1.reset_index(inplace=True)\n",
    "\n",
    "        df1.to_csv('localsave/fix_'+each, index=False, header=False)\n",
    "    except:\n",
    "        print(each)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving the files back to GCS bucket**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://localsave/fix_eval1.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave/fix_eval2.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave/fix_train0.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave/fix_train1.csv [Content-Type=text/csv]...\n",
      "|\n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://localsave/fix_train2.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave/fix_train3.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave/fix_train4.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave/fix_train5.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave/fix_train6.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave/fix_train7.csv [Content-Type=text/csv]...\n",
      "-\n",
      "Operation completed over 10 objects/456.9 MiB.                                   \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp localsave/fix_* gs://nyc_servicerequest/encodedInput/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test one file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://nyc_servicerequest/encodedInput/train0.csv...\n",
      "/ [1 files][ 45.9 MiB/ 45.9 MiB]                                                \n",
      "Operation completed over 1 objects/45.9 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://nyc_servicerequest/encodedInput/train0.csv data/demo2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>79.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   10  11  12      13\n",
       "0   2   1   1   1   3   2   0   0   1   0   0   0   1   1.273\n",
       "1   5   1   3   1   3   2   0   0   1   0   0   0   1  85.838\n",
       "2   6   1   3   1   3   2   1   0   0   0   1   0   0  59.059\n",
       "3   9   1   3   1   3   2   1   0   0   0   0   0   1  79.434\n",
       "4  10   1   0   1   2   2   0   0   1   0   0   0   1  26.400"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/demo2.csv', header=None).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Files for the Training and Evaluation finally stored to the bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For using the sklearn model, the features and class Labels must be used seperately. i.e. df.iloc[:, :-1] in one file, and df.iloc[:, -1] in another file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   10  11  12      13\n",
       "0   0   3   3   0   3   1   1   0   0   0   0   0   1  22.433\n",
       "1   4   3   3   0   2   1   0   0   1   0   0   0   1  13.531\n",
       "2   6   3   0   0   3   1   1   0   0   0   0   0   1  22.133\n",
       "3   7   3   3   0   3   1   0   1   0   0   1   0   0  65.283\n",
       "4   8   3   3   0   3   1   0   0   0   1   0   1   0  37.917"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('localsave/fix_eval1.csv', header=None).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_(filename):\n",
    "    df = pd.read_csv(filename, header=None)\n",
    "    return df.iloc[:, :-1], df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files = os.listdir('localsave/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for i in range(len(list_of_files)):\n",
    "    each = list_of_files[i]\n",
    "    if 'fix_' in each: \n",
    "        x, y = func_('localsave/'+each)\n",
    "        x.to_csv('localsave2/x_train'+str(j)+'.csv', header=None, index=None)\n",
    "        y.to_csv('localsave2/y_train'+str(j)+'.csv', header=None, index=None)\n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To read file\n",
    "#pd.read_csv('localsave2/x_eval1.csv', header=None).iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the files in the GCP Storage bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://localsave2/x_train0.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/x_train1.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/x_train2.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/x_train3.csv [Content-Type=text/csv]...\n",
      "/\n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://localsave2/x_train4.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/x_train5.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/x_train6.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/x_train7.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/x_train8.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/x_train9.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_train0.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_train1.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_train2.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_train3.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_train4.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_train5.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_train6.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_train7.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_train8.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_train9.csv [Content-Type=text/csv]...\n",
      "/\n",
      "Operation completed over 20 objects/442.4 MiB.                                   \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp localsave2/* gs://nyc_servicerequest/sklearnInput/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('localsave2/x_train0.csv', header=None).iloc[:, 1:]\n",
    "b = pd.read_csv('localsave2/x_train1.csv', header=None).iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2380564, 12), (1191200, 12), (1189364, 12))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([a, b]).shape, a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv('localsave2/y_train0.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging all the points and saving it in one file for the Job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = pd.DataFrame()\n",
    "ys = pd.DataFrame()\n",
    "\n",
    "xeval = pd.DataFrame()\n",
    "yeval = pd.DataFrame()\n",
    "\n",
    "for each in list(os.listdir('localsave2')):\n",
    "    each = 'localsave2/'+each\n",
    "    if('x_train' in each):\n",
    "        a = pd.read_csv(each, header=None).iloc[:, 1:]\n",
    "        xs = pd.concat([xs, a])\n",
    "    elif('y_train' in each):\n",
    "        a = pd.read_csv(each, header=None)\n",
    "        ys = pd.concat([ys, a])\n",
    "    elif('y_eval' in each):\n",
    "        a = pd.read_csv(each, header=None)\n",
    "        yeval = pd.concat([yeval, a])\n",
    "    elif('x_eval' in each):\n",
    "        a = pd.read_csv(each, header=None).iloc[:, 1:]\n",
    "        xeval = pd.concat([xeval, a])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9526573, 12), (9526573, 1), (2380440, 12), (2380440, 1))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape, ys.shape, xeval.shape, yeval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs.to_csv('localsave2/x_all_train.csv')\n",
    "ys.to_csv('localsave2/y_all_train.csv')\n",
    "xeval.to_csv('localsave2/x_all_eval.csv')\n",
    "yeval.to_csv('localsave2/y_all_eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://localsave2/x_all_eval.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/x_all_train.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run\n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "Copying file://localsave2/x_eval1.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/x_eval2.csv [Content-Type=text/csv]...\n",
      "-\n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://localsave2/x_train0.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/x_train1.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/x_train2.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/x_train3.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/x_train4.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/x_train5.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/x_train6.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/x_train7.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_all_eval.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_all_train.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_eval1.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_eval2.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_train0.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_train1.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_train2.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_train3.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_train4.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_train5.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_train6.csv [Content-Type=text/csv]...\n",
      "Copying file://localsave2/y_train7.csv [Content-Type=text/csv]...\n",
      "\\\n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "\n",
      "Operation completed over 24 objects/974.5 MiB.                                   \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp localsave2/* gs://nyc_servicerequest/sklearnInput/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67.710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0  79.386\n",
       "1  27.974\n",
       "2  85.845\n",
       "3  80.797\n",
       "4  67.710"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('localsave2/y_all_eval.csv').iloc[:, 1:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Code for the Model \n",
    "**DO NOT RUN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Fill in your Cloud Storage bucket name\n",
    "BUCKET_NAME = 'nyc_servicerequest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filename = 'x_all_train.csv'\n",
    "target_filename = 'y_all_train.csv'\n",
    "data_dir = 'gs://nyc_servicerequest/sklearnInput'\n",
    "\n",
    "# gsutil outputs everything to stderr so we need to divert it to stdout.\n",
    "subprocess.check_call(['gsutil', 'cp', os.path.join(data_dir, data_filename), data_filename], stderr=sys.stdout)\n",
    "\n",
    "subprocess.check_call(['gsutil', 'cp', os.path.join(data_dir, target_filename), target_filename], stderr=sys.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = pd.DataFrame()\n",
    "ys = pd.DataFrame()\n",
    "\n",
    "files = list(os.listdir(os.curdir))\n",
    "\n",
    "for each in files:\n",
    "    if('x_train' in each):\n",
    "        a  = pd.read_csv(each, header=None).iloc[:, 1:]\n",
    "        xs = pd.concat([xs, a])\n",
    "    elif('y_train' in each):\n",
    "        a = pd.read_csv(each, header=None)\n",
    "        ys = pd.concat([ys, a])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into pandas, then use `.values` to get NumPy arrays\n",
    "data = xs.values\n",
    "target = ys.values\n",
    "\n",
    "# Convert one-column 2D array into 1D array for use with scikit-learn\n",
    "target = target.reshape((target.size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "dec = DecisionTreeRegressor(verbose=True)\n",
    "dec.fit(data, target)\n",
    "\n",
    "#Export the classifier to a file\n",
    "model_filename = 'model.joblib'\n",
    "joblib.dump(dec, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(classifier, model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the saved model file to Cloud Storage\n",
    "gcs_model_path = os.path.join('gs://', BUCKET_NAME, 'models',\n",
    "    datetime.datetime.now().strftime('iris_%Y%m%d_%H%M%S') , model_filename)\n",
    "subprocess.check_call(['gsutil', 'cp', model_filename, gcs_model_path],\n",
    "    stderr=sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do not run locally till this point.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure you put the correct values here !!!\n",
    "BUCKET='nyc_servicerequest'\n",
    "PROJECT='summerai'\n",
    "REGION='us-west1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run trainer Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code to run the model locally. I won't do that since that's a lot of data, and I want to leave the computation to CloudML, still I will write down the commands below. You can run it if you want to test your model before submitting it to Jobs and consider fixing the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_PACKAGE_PATH='./DecisionTreeTrainer/'\n",
    "MAIN_TRAINER_MODULE='DecisionTreeTrainer.training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud ai-platform local train \\\n",
    "    --package-path $TRAINING_PACKAGE_PATH \\\n",
    "    --module-name $MAIN_TRAINER_MODULE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "BUCKET_NAME=\"nyc_servicerequest\"\n",
    "JOB_NAME=\"decision_tree_$(date +\"%Y%m%d_%H%M%S\")\"\n",
    "JOB_DIR=gs://$BUCKET_NAME/temp/\n",
    "TRAINING_PACKAGE_PATH=\"./DecisionTreeTrainer/\"\n",
    "MAIN_TRAINER_MODULE=\"DecisionTreeTrainer.training\"\n",
    "REGION=us-west1\n",
    "RUNTIME_VERSION=1.14\n",
    "PYTHON_VERSION=2.7\n",
    "SCALE_TIER=BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: decision_tree_20190727_230952\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [decision_tree_20190727_230952] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe decision_tree_20190727_230952\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs decision_tree_20190727_230952\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ai-platform jobs submit training \"decision_tree_$(date +\"%Y%m%d_%H%M%S\")\" \\\n",
    "--job-dir=gs://nyc_servicerequest/temp/ \\\n",
    "--package-path=./DecisionTreeTrainer/ \\\n",
    "--module-name=DecisionTreeTrainer.training \\\n",
    "--region=us-west1 \\\n",
    "--runtime-version=1.14 \\\n",
    "--python-version=2.7 \\\n",
    "--scale-tier=BASIC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify your model file in Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://nyc_servicerequest/models/\n",
      "gs://nyc_servicerequest/models/decision_tree_20190727_231218/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://nyc_servicerequest/models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying the model to AI Platform for online predicitons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model is already saved in Cloud Storage .  \n",
    "- Create a model Resource on AI Platform .  \n",
    "- Create a model version, linking the saved model .  \n",
    "- Make online predictions .  \n",
    "- Check the accuracy .  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a model resource for your model versions, filling in your desired name for the model without enclosing brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The `gcloud ml-engine` commands have been renamed and will soon be removed. Please use `gcloud ai-platform` instead.\n",
      "WARNING: `--regions` flag will soon be required. Please explicitly specify a region. Using [us-central1] by default.\n",
      "Created ml engine model [projects/summerai/models/decision_tree_model_1].\n",
      "Creating version (this might take a few minutes)......\n",
      "...............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "REGION='us-west1'\n",
    "MODEL_NAME='decision_tree_model_1'\n",
    "MODEL_VERSION='v1'\n",
    "FRAMEWORK='SCIKIT_LEARN'\n",
    "gcloud ml-engine models create $MODEL_NAME\n",
    "MODEL_LOCATION=$(gsutil ls gs://nyc_servicerequest/models/ | tail -1)\n",
    "\n",
    "gcloud ai-platform versions create $MODEL_VERSION \\\n",
    "--model $MODEL_NAME \\\n",
    "--origin $MODEL_LOCATION \\\n",
    "--runtime-version=1.14 \\\n",
    "--framework $FRAMEWORK \\\n",
    "--python-version=2.7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get information about the new version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2019-07-27T23:29:54Z'\n",
      "deploymentUri: gs://nyc_servicerequest/models/decision_tree_20190727_231218/\n",
      "etag: RAvQjIdybsA=\n",
      "framework: SCIKIT_LEARN\n",
      "isDefault: true\n",
      "machineType: mls1-c1-m2\n",
      "name: projects/summerai/models/decision_tree_model_1/versions/v1\n",
      "pythonVersion: '2.7'\n",
      "runtimeVersion: '1.14'\n",
      "state: READY\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ai-platform versions describe v1 \\\n",
    "--model='decision_tree_model_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Deployed Model](Images/5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model is finally Deployed :) :) :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send online Prediction Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to check the predictions for our Test/Eval datasets to see how the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = pd.read_csv('localsave2/x_all_eval.csv', header=None).iloc[1:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_features = test1.as_matrix().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_labels = pd.read_csv('localsave2/y_all_eval.csv', header=None).iloc[1:, 1:]\\\n",
    "                .as_matrix().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23804.4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_features)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 30.373710374885594\t\tActual: 79.38600000000002\n",
      "Prediction: 35.84330128427631\t\tActual: 27.974\n",
      "Prediction: 35.14199171671147\t\tActual: 85.845\n",
      "Prediction: 38.73326135615535\t\tActual: 80.797\n",
      "Prediction: 36.035388609715234\t\tActual: 67.71\n",
      "Prediction: 21.873060107837222\t\tActual: 15.383\n",
      "Prediction: 22.253109202714228\t\tActual: 22.483\n",
      "Prediction: 22.446519035223197\t\tActual: 14.45\n",
      "Prediction: 22.446519035223197\t\tActual: 1.867\n",
      "Prediction: 20.00250884152769\t\tActual: 32.189\n"
     ]
    }
   ],
   "source": [
    "import googleapiclient.discovery\n",
    "\n",
    "# Fill in your PROJECT_ID, VERSION_NAME and MODEL_NAME before running\n",
    "# this code.\n",
    "PROJECT_ID = 'summerai'\n",
    "VERSION_NAME = 'v1'\n",
    "MODEL_NAME = 'decision_tree_model_1'\n",
    "\n",
    "service = googleapiclient.discovery.build('ml', 'v1')\n",
    "name = 'projects/{}/models/{}'.format(PROJECT_ID, MODEL_NAME)\n",
    "name += '/versions/{}'.format(VERSION_NAME)\n",
    "\n",
    "\"\"\"\n",
    "Sample features - \n",
    "['zip_encode', 'location_encode', 'community_encode', 'agency_encode',\n",
    "'complaint_encode', 'afternoon', 'evening', 'morning', 'night', 'Fri-Sat-Sun', 'Mon-Tue', 'Wed-Thu']\n",
    "[0, 3, 1, 0, 2, 0, 1, 0, 0, 0, 1, 0]        \n",
    "\"\"\"\n",
    "data = test_features[:int(len(test_features)/100)] # pandas_dataframe(list[list])\n",
    "\n",
    "responses = service.projects().predict(name=name, body={'instances': data}).execute()\n",
    "\n",
    "if 'error' in responses:\n",
    "    print(response['error'])\n",
    "else:\n",
    "    # Print the first 10 responses\n",
    "    for i, response in enumerate(responses['predictions'][:10]):\n",
    "        print('Prediction: {}\\t\\tActual: {}'.format(response, test_labels[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_anaylsis(y_pred, y_actual):\n",
    "    # mean squared error\n",
    "    m = len(y_actual)\n",
    "    \n",
    "    mse = np.sum((y_pred - y_actual)**2)\n",
    "\n",
    "    # root mean squared error\n",
    "    # m is the number of training examples\n",
    "    rmse = np.sqrt(mse/m)\n",
    "    \n",
    "    # sum of square of residuals\n",
    "    ssr = np.sum((y_pred - y_actual)**2)\n",
    "\n",
    "    #  total sum of squares\n",
    "    sst = np.sum((y_actual - np.mean(y_actual))**2)\n",
    "\n",
    "    # R2 score\n",
    "    r2_score = 1 - (ssr/sst)\n",
    "    \n",
    "    return mse, rmse, ssr, sst, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse, rmse, ssr, sst, r2_score = error_anaylsis(responses['predictions'], np.concatenate(test_labels[:int(len(test_features)/100)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for the Decision Tree model on the whole dataset  29.208398873435645\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE for the Decision Tree model on the whole dataset \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
