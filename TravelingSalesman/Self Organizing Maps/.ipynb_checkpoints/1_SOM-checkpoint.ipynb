{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Self-Organizing Maps to solve the Traveling Salesman Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traveling Salesman Problem**\n",
    "- NP-Complete   \n",
    "- Traverses all cities in a given map only once .  \n",
    "- Difficulty increases with increase in Number of cities   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SOM](som.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Self Organizing Maps**\n",
    "- SOM is a grid of nodes. Closely related to the idea of a model, that is, the real-world observation the map is trying to represent.   \n",
    "The purpose is to represent the model with a lower number of dimensions, while maintaining the relations of similarity of the nodes contained in it.   \n",
    "   \n",
    "- More similar the nodes, more spatially closer they are organized.Hence, it makes SOM good for pattern visualization and organization of data.   \n",
    "   \n",
    "- To obtain the structure, the map is applied a regression operation to modify the nodes position in order to update the nodes, one element from the model at a time.   \n",
    "   \n",
    "- The position of the node is updated adding the distance from it to the given element x Neighbourhood Factor of the winner Neuron. \n",
    "\n",
    "- SOMs are used for Dimensionality Reduction and Dense Vector Representations of the data.   \n",
    "   \n",
    "- They are different from the Neural Networks because of the technique they used to learn, unlike NN which uses Backpropogation with Gradient Descent, **SOMs use Neigbourhood-based techniques to preserve topological properties of the input space.**   \n",
    "   \n",
    "- SOMs retain Topology and reveal correlations. They Classify data without Supervision. No Target Vector -> No Backprop. No Lateral connections (No Neural Network connection) between the output nodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm:   \n",
    "1. Each node's weights are initialized.   \n",
    "2. A vector is chosen at random from the set of training data.   \n",
    "3. Every node is examined to calculate which one's weight are most like the input vector. The winning node is commonly known as the **BEST Matching Unit (BMU)**\n",
    "4. Then the neighbourhood of the BMU is calculated. The amount of neighbors decrease over the time.   \n",
    "5. The winning Node is rewarded with becoming more like the sample vector. The neighbours also become more like the sample vector. The closer a node is to the BMU, the more its weight get altered and the farther away the neighbor is from the BMU the less it learns.   \n",
    "6. Repeat step 2 for N Iterations.   \n",
    "   \n",
    "   \n",
    "***Best Matching Unit*** is a technique which calculates the distance from each weight to the sample vector, by running through all weight vectors. The weight with the shortest distance is the winner.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modifying the technique:** \n",
    "To use the network to solve the TSP, the main concept is to understand how to modify the neighbourhood function. If instead of a grid we declare a circular array of neurons, each node will only be concious of the neurons in front of and behind it. That is, the inner similarity will work just in one dimension. Making this slight modification, the SOM will behave as an elastic ring, getting closer to the cities but trying to minimize the perimeter of it thanks to the neighbourhood function.   \n",
    "\n",
    "**NEIGHBORHOOD FUNCTION AND LEARNING RATE**   \n",
    "- It is used to control the exploration and exploitation of the algorithm.   \n",
    "- To obtain high exploration first and high exploitation after that in the execution, we must include a decay in both the neighborhood function and the learning rate.   \n",
    "- Decaying the Learning rate will ensure less aggressive displacement of the neurons around the model.   \n",
    "- Decaying the neighbourhood will result in a more moderate exploitation of the local minima of each part of the moddel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO ASSOCIATE THE CITY WITH ITS WINNER NEURON, TRANSVERSE THE RING STARTING FROM ANY POINT AND SORT THE CITIES BY ORDER OF APPEARANCE OF THEIR WINNER NEURON IN THE RING. IF SEVERAL CITIES MAP TO THE SAME NEURON, IT IS BECAUSE THE ORDER OF TRANSVERSING SUCH CITIES HAVE NOT BEEN COMTEMPLATED BY THE SOM. IN THAT CASE, ANY POSSIBLE ORDER CAN BE CONSIDERED.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfOrganizingMap: \n",
    "    def read_data(self, count):\n",
    "        df = pd.read_csv('../data.csv', header=None) \n",
    "        nodes = []\n",
    "        for i in range(len(df[0])):\n",
    "            sp = df[0][i].split(' ')\n",
    "            x = float(sp[1])\n",
    "            y = float(sp[2])\n",
    "            nodes.append([x, y])\n",
    "        nodes = nodes[:count]   \n",
    "        return pd.DataFrame(nodes, columns=['x', 'y'])\n",
    "    \n",
    "    \n",
    "    def normalize(self, points):\n",
    "        \"\"\"Return the normalized version of a given vector of points\"\"\"\n",
    "        ratio = (points['x'].max() - points['x'].min()) / (points['y'].max() - points['y'].min()), 1\n",
    "        ratio = np.array(ratio) / max(ratio)\n",
    "        norm = points.apply(lambda c: (c - c.min()) / (c.max() - c.min()))\n",
    "        return norm.apply(lambda p: ratio * p, axis=1)\n",
    "    \n",
    "    \n",
    "    def select_closest(self, candidates, origin):\n",
    "        \"\"\"Return the index of the closest candidate to a given point\"\"\"\n",
    "        return self.eucledian_distance(candidates, origin).argmin()\n",
    "\n",
    "    \n",
    "    def eucledian_distance(self, a, b):\n",
    "        return np.linalg.norm(a - b, axis = 1)\n",
    "    \n",
    "    \n",
    "    def route_distance(self, cities):\n",
    "        \"\"\"Return the cost of traversing a route of cities in a certain order\"\"\"\n",
    "        points = cities[['x', 'y']]\n",
    "        distances = self.eucledian_distance(points, np.roll(points, 1, axis=0))\n",
    "        return np.sum(distances)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def generate_network(self, size):\n",
    "        \"\"\"\n",
    "        Generate neuron network for a given size\n",
    "        Return a vector of 2-D points in the interval of [0,1]\n",
    "        \"\"\"\n",
    "        return np.random.rand(size, 2)\n",
    "\n",
    "    \n",
    "    def get_neighborhood(self, center, radix, domain):\n",
    "        \"\"\"Get the range gaussian of given radix around a center index\"\"\"\n",
    "        if radix < 1: radix = 1\n",
    "        deltas = np.absolute(center - np.arange(domain))\n",
    "        distances = np.minimum(deltas, domain - deltas)\n",
    "        return np.exp(-(distances*distances) / (2*(radix*radix)))\n",
    "\n",
    "    \n",
    "    def get_route(self, cities, network):\n",
    "        \"\"\"Return the route computed by a network\"\"\"\n",
    "        cities['winner'] = cities[['x', 'y']].apply(\n",
    "            lambda c: self.select_closest(network, c), \n",
    "            axis=1, raw=True)\n",
    "        return cities.sort_values('winner').index\n",
    "    \n",
    "        \n",
    "        \n",
    "    def som(self, problem, iterations, learning_rate=0.8):\n",
    "        \"\"\"Solve the TSP using a Self-Organizing Map.\"\"\"\n",
    "\n",
    "        # Obtain the normalized set of cities (w/ coord in [0,1])\n",
    "        cities = problem.copy()\n",
    "\n",
    "        cities[['x', 'y']] = self.normalize(cities[['x', 'y']])\n",
    "\n",
    "        # The population size is 8 times the number of cities\n",
    "        n = cities.shape[0] * 8\n",
    "\n",
    "        # Generate an adequate network of neurons:\n",
    "        network = self.generate_network(n)\n",
    "        #print('Network of {} neurons created. Starting the iterations:'.format(n))\n",
    "\n",
    "        for i in range(iterations):\n",
    "            if not i % 100:\n",
    "                print('\\t> Iteration {}/{}'.format(i, iterations), end=\"\\r\")\n",
    "            # Choose a random city\n",
    "            city = cities.sample(1)[['x', 'y']].values\n",
    "            winner_idx = self.select_closest(network, city)\n",
    "            # Generate a filter that applies changes to the winner's gaussian\n",
    "            gaussian = self.get_neighborhood(winner_idx, n//10, network.shape[0])\n",
    "            # Update the network's weights (closer to the city)\n",
    "            network += gaussian[:,np.newaxis] * learning_rate * (city - network)\n",
    "            # Decay the variables\n",
    "            learning_rate = learning_rate * 0.99997\n",
    "            n = n * 0.9997\n",
    "\n",
    "            # Check if any parameter has completely decayed.\n",
    "            if n < 1:\n",
    "                #print('Radius has completely decayed, finishing execution',\n",
    "                #'at {} iterations'.format(i))\n",
    "                break\n",
    "            if learning_rate < 0.001:\n",
    "                #print('Learning rate has completely decayed, finishing execution',\n",
    "                #'at {} iterations'.format(i))\n",
    "                break\n",
    "        else:\n",
    "            pass\n",
    "        route = self.get_route(cities, network)\n",
    "        self.plot_route(cities, route, 'route.png')\n",
    "        return route\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network of 4000 neurons created. Starting the iterations:\n",
      "Radius has completely decayed, finishing execution at 27642 iterations\n",
      "Shortest distance 19988.001850987184\n",
      "Time spend for finding shortest distance 42.00268220901489\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "maps = SelfOrganizingMap()\n",
    "\n",
    "nodes = maps.read_data(500)\n",
    "route = maps.som(nodes, 100000)\n",
    "nodes1 = nodes.reindex(route)\n",
    "distance = maps.route_distance(nodes1)\n",
    "\n",
    "print('Shortest distance', distance)\n",
    "time_lapse = time.time() - start\n",
    "print('Time spend for finding shortest distance', time_lapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: \n",
    "1. https://github.com/DiegoVicen/som-tsp   \n",
    "2. https://towardsdatascience.com/self-organizing-maps-ff5853a118d4\n",
    "3. https://diego.codes/post/som-tsp/   \n",
    "4. https://www.youtube.com/watch?v=9ZhwKv_bUx8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
